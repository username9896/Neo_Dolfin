Please find here a summary of contributions of students, that will be later uploaded directly to the word document for our Company Progress reports. 

## Contributions

How do you order your contributions? Use the template of Ordered or Unordered Lists below and input your own work. It is important for the table to continue that your input only takes up the space of one line - otherwise the table will break. Take the following examples, Lines 20, 23, 29, 37 and 41 which I've done and you'll see that the lines are incredibly long. That's how it's meant to be. Of course, ordering or listing the contributions isn't necessary. You might just include a paragraph. It is totally up to you! 

Once you write it here, feel free to paste it directly into the main report document via a commit and then PR. 
This page is for clarity and understanding of how to add your contributions to the table in the report markdown document.

Ordered List
<ol type="1"><li>Item 1</li><li>Item 2</li><li>Item 3</li><li>Item 4</li><li>Item 5</li><li>Item 6</li></ol>

Unordered List
<li>Item 1</li><li>Item 2</li><li>Item 3</li><li>Item 4</li><li>Item 5</li><li>Item 6</li>
<br></br>

<details> 
  
<summary>Sprint 1 and 2 Contributions</summary> 

| Name                  | Contributions|
|:-------------|:-------------------|
| Aishwarya Mahajan   |• Python Mastery: Enhanced my proficiency with critical Python libraries such as NumPy and Pandas, crucial for data analysis and manipulation tasks. This skill set allows for advanced data processing capabilities within the DolFin project.• Created Python Script for Data Quality: Developed a Python script specifically for data dictionary validations and will be enhancing it further with upcoming data fields. This script ensures that incoming data adheres to established quality standards, significantly enhancing data integrity and reliability.• Machine Learning Algorithms: Invested time to understand and implement machine learning algorithms, building a base for the development of predictive models that can influence financial outcomes and decision-making processes.• Data Validation Automation: Script that automates the data validation process for the DolFin project. This tool improves the efficiency and accuracy of data quality checks, streamlining data operations and ensuring compliance with data standards.|
| Amandeep Kaur Sandhu|  <ol type="1"><li>Conducted extensive market research and competitor analysis to identify unique                                                                                                                                        opportunities for DolFin, enhancing its competitive edge in the fintech ecosystem.</li><li>implemented advanced data science techniques to enhance the performance of financial transaction classification models.</li><li>Developed alternative visualization methods for model performance to provide intuitive insights for the DolFin team.</li><li> Identified new applications for the model output, adding value to DolFin staff in their day-to day decision-making and strategic planning.</li></ol>   |
| Armaan Chetal |               |
| Asma Alsheddi |               |
| Ata Colak     | Fixed issues in a few queries in the chatbot which causes it to not give a response and sent a PR. Taken the co-lead of the chatbot project. Still working on implementing a more comprehensive chatbot model to DolFin while keeping in close touch with AI stream lead and chatbot co-lead Axesh. |
| Axesh Patel   |<ol type="1"><li>Conducted market research for Dolfin app's financial well-being segment</li><li>Analyzed market trends, user preferences, and competitor offerings</li><li>Prepared a detailed report with findings and recommendations</li><li>Researched and evaluated new Language Models (LLMs) for chatbot enhancement </li><li>Explored various LLMs to identify potential replacements for the existing chatbot</li><li>Selected and implemented LLAMA2 LLM for chatbot replacement</li><li>Chose LLAMA2 as the most promising LLM after careful evaluation</li><li> Developed a basic chatbot prototype using LLAMA2</li><li>Pushed updated chatbot code to project's GitHub repository for version control and collaboration </li><li>Explored Generative Adversarial Networks (GANs) for synthetic transactional data generation</li><li>Researched GANs' application in generating synthetic transactional data </li><li>Implemented a GAN-based solution and experimented with different hyperparameters but didn't got expected outcomes</li><li>Investigated LLAMA.CPP library for enhanced chatbot flexibility </li><li>Explored LLAMA.CPP library to make the chatbot more flexible and customizable</li><li>Encountered unexpected errors in LLAMA.CPP and working on resolving them.</li></ol>|
| Ben Bradhurst |               |
| Damion De Motte | - Getting up to speed with regards to current requirements in the Dolfin project/product - Conducting research on SQLiute and more specifically parameterised queries and how it can be applicable to Dolfin -Pivoting research to MongoDB and how it may be more beneficial due to the decision to opt to use it |
| Darasana Prakash |               |
| Deepak Kumar Khatri | 1. Designed Registeration Page using Figma 2. Worked on market Research Task by working on to Find Market Compititors add reference designs. 3.Created a document outlining the purpose and information required for the registration page. 4. Helped fellow students with the  issues they were facing. 5. Finished Signout Route Task and pull request was approved. 6. Finished Clear Transaction Optimization and sent pull request to Github|
| Denica Hope | <li>Assisted with the onboarding presentation.</li><li>Created Trello cards for Market Research stream</li><li>Conducted Market Research on Financial Wellbeing in Tech Apps and prepared an individual research report.  </li><li>Prepared a consolidated summary of all market research submissions and a powerpoint to present overall findings </li><li>Hosted meetings with Market Research stream to provide clarity on tasks</li><li>Hosted meetings for Data Science/AI streams</li><li>Researched how to generate random financial data </li><li>Created Trello cards for Data Science/AI streams </li><li>Created a randomly generated home loan data set and credit card data set</li><li>Research how to consolidate payment transactions from these datasets into general transaction data set that will also include other randomly generated transactions and transaction classification categories.</li><li>Meet with Product Owner and mentor to discuss product and tasks</li><li>Assist other students with general questions about the unit or specific questions about Trello tasks. </li> |
| Divanshi Divanshi |               |
| Faysal Bhatti |               |
| Gia Nguyen Phung | -Decode tokens to words in transaction classification -Display distribution of classess after importing the dataset|
| Gimsara Elgiriyage |  * Assisted with the onboarding presentation. * Met with the Dolfin Leadership team to discuss the responsibility of leaders, the content of the onboarding presentation, and future schedule* Created Trello cards for Front End stream.* Conducted Market Research on UI of financial wellbeing applications and created a report.* Hosted meetings with the Front End stream to provide clarity on tasks and help peers.* Met with Product Owner and mentor to discuss product and tasks.* Assisted other students with general questions about the unit to help them get onboard with ease or specific questions about Trello tasks.* Came up with new UI/UX features and presented them to Kelvin.* Corrected a broken route in the web app.* Added sign up and login animations.* Started working on a feature to allow users to leave reviews.* Appointed a sub team to work on the conversion of HTML/CSS to React. |
| Gunjan Sharma |               |
| Hassaan Syed  | * Created privacy policy * contributed to report on Global Hashing Pepper|
| Heera Mohanadas | <li>Created data governance policy</li><li>Created password policy </li><li>Created Trello tasks and proposed technical features to the product owner and project mentors </li><li>Created password complexity requirements and coded them into Dolfin's registration page - with an accompanying feature report explaining code</li><li>Assisted with the onboarding presentation and hosted onboarding presentation with other leads for students </li><li>Attended meetings and discussed product and features for security development with Product Owner and Mentors</li><li>Assisted other students with general questions concerning the unit, troubleshooting questions, and aid for Trello Tasks</li><li>Finished the Dolfin section of the 6.1P Company progress report </li><li>Created the base of the markdown to collect student contributions for Sprints   </li>|
| Imran Mughal |               |
| Jack Genesin | Conducted market research on Financial Wellbeing and produced a report highlighting the findings, along with competitor examples - Wrote a Python script for generating randomised Home Loan account datasets. Created 'User C' Home Loan profile and generated a Home Loan account dataset for them -Wrote a Python script for generating randomised Credit Card account datasets. In the process of creating 'User C's Credit Card profile and generating a Credit Card dataset for them - still in the works|
| Jensen Tang |               |
| Junkai Jiang |  <ol type="1"><li>Fix the shadow image issue</li><li>Coordinate week 0 company presentation</li><li>Clean up Trello Board</li><li>Clean up GitHub </li><li>Meet with the Dolfin Leadership team (Discuss the responsibility of leaders, the content of the onboarding presentation, and future schedule) </li><li>Meet with product owner Kelvin Li (Discuss the current situation about Dolfin)</li><li>Apply the budget request of Dolfin</li><li>Set up the market research squad and publish related Trello cards </li><li>Prepare onboarding presentation </li><li>Write a post about how to configure the access token </li><li>Clean up abandoned code </li><li>Rebuild and deploy the DB and API module</li><li> Onboarding presentation (BE part) Publish Trello cards related to BE for week 3</li><li>Coordinate and be responsible for onTrack task2.1 P </li><li> Prepare for the week 3 presentation about how Dolfin works</li><li>Contact the Basiq team for more information </li><li>Reported financial well-being survey prototypeGive a tutorial about how Dolfin run </li><li>Contact Basiq teamOrganise the database structure from the report and submit it to Kelvin Li</li><li>Use React to build the Dolfin_new front-end framework </li><li>Use Flask to build the Dolfin_new back-end framework </li><li>Use nginx as the Dolfin_new webserverUse docker to containerise the Dolfin_new </li><li>Review the pull request for rebuilding the sign-out routeWeekly BE Stream meeting /li><li>Write notes about dolfin_new</li><li>Nominate BE co-leader</li></ol> |
| Krish  |               |
| Liny Jose Alias |1)Upskilling in Data Wrangling skills. 2)Building Expertise in Machine Learning Model implementation. 3)Learning Data Generation using Python. 4)Currently working on the Data Generation card where a user story is created and Data generated using python based on the User Story. 5)Active participation in Meetings and Team Collaboration.|
| Muhammad Ali Saad  |               |
| Muhammad Saad Saad |               |
| Nick Lane |               |
| Pradipta Dutta |               |
| Ricky Boeing |               |
| Sagar Gupta |               |
| Sahana Gollapalli |               |
| Samruddhi Bhor | 1. Conducted hyperparameterization to optimize dropout and dense layer configurations for an NLP model aimed at classifying transactions based on description. 2. Configured TensorFlow to log performance scores for each hyperparameter combination. 3. Developed functionality to automatically save the best performing model based on validation scores. 4. Undertook the leadership role of representing DolFin in weekly Monday meetings, providing comprehensive updates on the progress of all streams within DolFin. 5. Acted as a key reviewer for data and AI-related pull requests on GitHub, ensuring quality and adherence to standards. 6. Collaborated with the DS/AI leader, Denica, to discuss and provide insights on Trello cards, contributing to effective project management and decision-making processes. |
| Sri Harsha Vardhan Nimmalapudi | • Generated individual market research report on market competitor identifying the key components required for a financial well being application. •  Changing the sentiment analysis to multiclass classification. •  Used hyperparameters to identify the better combinations of dropout and dense layers.  • Joined weekly team meetings to volunteer for tasks and update on the progress of work. • Logged the score for each hyperparameter combination and setup tensorflow to display it.  • Written code to save the parameters and the weights of the best performing model. • Decoded tokens to generate sentences of text back from the tokenisation done in the initial phase of the model. • Generated word clouds for 3 different sentiments and made plots to display the distribution of the dataset.  • Implemented BERT model from pretrained BERT tokenizer using bert-base-uncased. • Used the same adam optimizer and categorical crossentropy loss on the model to compare it in a similar environment to the LSTM model.      • Created a pull request with all the changes made to the sentiment analysis model in github. |
| Sushant Dudeja |               |
| Tingting Lu | * Attended meetings with team leaders and mentors to understand tasks need to complete. * Participated squad meetings for the tasks addressed in Trello * Researched front end design trend for financial products  * Completed individual market research report |
| Vicky Kumar |               |
| Vishal Kumar | • Participated in meetings with mentors and team leaders to understand project requirements. • Had communication and interacted with team leaders to address task-related issues or understand specific requirements. • Designed the registration page UI using Figma • Created a document outlining the purpose and information required for the registration page.  • Researched market competitors and identified areas for improvement based on competitor analysis.     • I implemented the registration page using HTML and CSS code. • After implementing the registration page using HTML and CSS, I noticed that it was not responsive enough. Therefore, I made the page responsive as well. |
| Yeni Waliatin |               |
| Yi Guan       |               |
| Zakarya Guerinat     |               |


</details>

<details>
  
<summary>Sprint 3&4 Contributions</summary>

Practice in this table or the other! It's totally up to you :D 
<br></br> 

| Name                  | Contributions|
|:-------------|:-------------------|
| Full name   | Write contributions here ! <li>ITEM 1</li><li>ITEM 2</li><li>ITEM 3</li><li>ITEM 4</li><li>ITEM 5</li><li>ITEM 6</li>|


| Name                  | Contributions|
|:-------------|:-------------------|
| Nicholas Lane   | Write contributions here ! <li>I developed a NLP model that uses transfer learning to classify transactions using a BERT transformer.</li><li>I wrote code to clean and preprocess text data, encode class labels, then tokenized transaction descriptions using BERT tokenizer, convert to BERT input format.</<li><li>Created a function to create datasets, create datasets for training, validation, and testing.</li><li>Loaded in the Pre-trained BERT Model: Load pre-trained BERT model for NLP classification, then added an output layer for class prediction.</li><li>Compiled and train the BERT model with training dataset and fine tuned the model and finally evaluated the performance of the model.</li><li>Updated the code to include the DolFin colour code format, and resubmitted the code</li><li>I development of a Deep Neural Network model to identify and classify fraudulent bank transactions.</li><li>I searched for a suitable dataset, that would contain the information that DolFin would be able to access through the Open Banking platform.</li><li>I write code to clean and preprocess the various data types and prepare them for the deep learning model.</li><li>I split the data into training and testing datasets which were then made into TensorFlow datasets, which had been shuffled and prefetched.</li><li>I developed a model and added regulation to improve the model’s generalizability and reduce overfitting to the training data.</li><li>>The model was compiled and then evaluated, I also updated the colours to the Dolfin colour format and then submitted the code as a .py file.</li><liAttended product owner meetings and team meetings</li><li>Assist with handover documentation and presentation slides.</li>|
  
</details>
